spring:
  application:
    name: tappha-backend
  main:
    allow-circular-references: true
  
  datasource:
    url: jdbc:postgresql://localhost:5432/tappha
    username: ${DB_USERNAME:tappha}
    password: ${DB_PASSWORD:tappha}
    driver-class-name: org.postgresql.Driver
    hikari:
      maximum-pool-size: 20
      minimum-idle: 5
      connection-timeout: 30000
      idle-timeout: 600000
      max-lifetime: 1800000

  jpa:
    hibernate:
      ddl-auto: create-drop
    show-sql: false
    properties:
      hibernate:
        dialect: org.hibernate.dialect.PostgreSQLDialect
        format_sql: true
        jdbc:
          batch_size: 50
        order_inserts: true
        order_updates: true

  flyway:
    enabled: false  # Temporarily disabled due to PostgreSQL 17.5 compatibility
    locations: classpath:db/migration
    baseline-on-migrate: true
    validate-on-migrate: true

  redis:
    host: localhost
    port: 6379
    password: ${REDIS_PASSWORD:}
    timeout: 5000
    lettuce:
      pool:
        max-active: 20
        max-idle: 10
        min-idle: 5
        max-wait: -1

# Kafka configuration for event processing
  kafka:
    bootstrap-servers: ${KAFKA_BOOTSTRAP_SERVERS:localhost:9092}
    consumer:
      group-id: tappha-homeassistant
      auto-offset-reset: earliest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      enable-auto-commit: true
      auto-commit-interval: 1000
      session-timeout: 30000
      heartbeat-interval: 10000
      max-poll-records: 500
      fetch-min-size: 1
      fetch-max-wait: 500
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      acks: all
      retries: 3
      batch-size: 16384
      buffer-memory: 33554432
      compression-type: snappy
      linger-ms: 10

  security:
    oauth2:
      client:
        registration:
          google:
            client-id: ${GOOGLE_CLIENT_ID}
            client-secret: ${GOOGLE_CLIENT_SECRET}
            scope:
              - email
              - profile
    # Disable WebSocket security for now to avoid compatibility issues
    websocket:
      security: false

server:
  port: 8080
  servlet:
    context-path: /api

management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,prometheus
  endpoint:
    health:
      show-details: when-authorized
  metrics:
    export:
      prometheus:
        enabled: true

logging:
  level:
    com.tappha: DEBUG
    org.springframework.security: DEBUG
    org.springframework.web: DEBUG
    org.hibernate.SQL: DEBUG
    org.hibernate.type.descriptor.sql.BasicBinder: TRACE
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss} - %msg%n"

# Home Assistant Integration Configuration
tappha:
  homeassistant:
    connection:
      timeout: 10000
      retry-attempts: 3
      retry-delay: 1000
    websocket:
      heartbeat-interval: 30000
      reconnect-delay: 5000
      max-reconnect-attempts: 10
    event-processing:
      batch-size: 100
      processing-delay: 100
      max-queue-size: 10000
    security:
      token-encryption-key: ${TOKEN_ENCRYPTION_KEY:default-key-change-in-production}
    monitoring:
      metrics-interval: 60000
      health-check-interval: 30000
  
  # WebSocket Configuration
  websocket:
    max-text-message-size: 8192
    max-binary-message-size: 8192
    idle-timeout: 600000
    max-sessions: 100
    heartbeat-interval: 30000
  
  # JWT Configuration
  jwt:
    secret: ${JWT_SECRET:default-jwt-secret-change-in-production}
    expiration: 86400000

# InfluxDB Configuration
influxdb:
  url: http://localhost:8086
  token: ${INFLUXDB_TOKEN}
  org: tappha
  bucket: tappha-metrics

# AI Processing Configuration
ai:
  onnx:
    enabled: false  # Disabled due to Alpine Linux compatibility issues
  hybrid:
    enabled: true
    local-first: true
    local-threshold: 0.7  # Use local processing for confidence >= 0.7
    fallback-enabled: true
  openai:
    api:
      key: ${OPENAI_API_KEY:}
      base-url: https://api.openai.com/v1
    models:
      primary: gpt-4o-mini
      fallback: gpt-3.5-turbo
    max-tokens: 1000
    temperature: 0.7
    timeout: 30000
    max-retries: 3
    rate-limit:
      requests-per-minute: 60
      tokens-per-minute: 150000
      burst-size: 10
  local:
    tensorflow-lite:
      enabled: false  # Will be enabled when TensorFlow Lite is implemented
      model-path: /models/pattern-classifier.tflite
      inference-timeout: 100  # ms
      confidence-threshold: 0.7
  caching:
    enabled: true
    ttl: 3600  # seconds (1 hour)
    max-size: 10000  # maximum number of cached responses
    key-prefix: "ai:suggestion:"
  batch:
    enabled: true
    schedule: "0 0 */6 * * *"  # Every 6 hours
    batch-size: 100
    max-concurrent-batches: 3
    processing-timeout: 300000  # 5 minutes
    retry-failed-suggestions: true

  spring-ai:
    openai:
      chat:
        options:
          model: gpt-4o-mini
          temperature: 0.7
          max-tokens: 1000
      embedding:
        options:
          model: text-embedding-3-small
          dimensions: 1536
    vectorstore:
      pgvector:
        dimensions: 1536
        distance-type: cosine
        index-type: ivfflat
        lists: 100 